{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "I6bLELHk0cSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normal ML model to compare the accuracy with the PHE and FHE encryption domain ML model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        " #data preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/archive/encoded_data.csv')\n",
        "df = df.drop(columns=['User_ID'])\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Predictions:\", y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1FcLY72LFPL",
        "outputId": "64e67d74-2b63-431c-9bdc-73126c49529f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1\n",
            " 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1\n",
            " 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0\n",
            " 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0\n",
            " 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0\n",
            " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1\n",
            " 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1\n",
            " 1 0 0 0]\n",
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Paillier partial Homomorphic Encryption\n",
        "!pip install phe\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from phe import paillier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        " #data preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/archive/encoded_data.csv')\n",
        "df = df.drop(columns=['User_ID'])\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target'].values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "#Training Logistic Regression Model with unencrypted  data\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "weights = model.coef_.flatten()\n",
        "intercept = model.intercept_[0]\n",
        "\n",
        "public_key, private_key = paillier.generate_paillier_keypair()\n",
        "encrypted_b = public_key.encrypt(intercept)\n",
        "\n",
        "#Normal dot product of weights and Test data\n",
        "dot_product = np.dot(X_test, weights)\n",
        "encrypted_dot_product = [public_key.encrypt(a) for a in dot_product]\n",
        "\n",
        "# Paillier PHE for handling addition operation on encrypted data\n",
        "def encrypted_inference(encrypted_dot_product, encrypted_b, private_key):\n",
        "    decrypted_predictions = []\n",
        "    for encrypted_a in encrypted_dot_product:\n",
        "        encrypted_sum = encrypted_a + encrypted_b\n",
        "        decrypted_value = private_key.decrypt(encrypted_sum)\n",
        "        decrypted_predictions.append(1 if decrypted_value > 0 else 0)\n",
        "    return decrypted_predictions\n",
        "\n",
        "decrypted_predictions = encrypted_inference(encrypted_dot_product, encrypted_b, private_key)\n",
        "\n",
        "accuracy = accuracy_score(y_test, decrypted_predictions)\n",
        "print(\"Decrypted predictions:\", decrypted_predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyX3NeQsLa69",
        "outputId": "bf82180f-06a8-4e58-8b71-de92ee2a1842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: phe in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Decrypted predictions: [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "Accuracy: 96.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4h-RWSvKZor",
        "outputId": "170a511f-f730-48a3-c339-f3538dd7970a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.15)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Accuracy: 97.00%\n"
          ]
        }
      ],
      "source": [
        "#CKKS Fully Homomorphic Encryption\n",
        "!pip install tenseal pandas scikit-learn torch torchvision --upgrade\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tenseal as ts\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#data preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/archive/encoded_data.csv')\n",
        "df = df.drop(columns=['User_ID'])\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target'].values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "#Training Logistic Regression Model with unencrypted  data\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Setting up the encryption domain\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192, #to avoid noise after operations\n",
        "    coeff_mod_bit_sizes=[60, 40, 40, 60] #used for rescaling after operations\n",
        ")\n",
        "context.global_scale = 2**40  #Scaling Factor to handle floating values\n",
        "context.generate_galois_keys()\n",
        "\n",
        "# Encrypting Test Data Batchwise\n",
        "def encrypt_batch(data, context, batch_size=500):\n",
        "    encrypted_data = []\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        batch = data[i:i+batch_size]\n",
        "        encrypted_batch = [ts.ckks_vector(context, row.tolist()) for row in batch]\n",
        "        encrypted_data.append(encrypted_batch)\n",
        "    return encrypted_data\n",
        "\n",
        "encrypted_X_test_batches = encrypt_batch(X_test, context)\n",
        "encrypted_weights = ts.ckks_vector(context, model.coef_[0].tolist())\n",
        "encrypted_bias = ts.ckks_vector(context, [model.intercept_[0]])\n",
        "\n",
        "# CKKS FHE for handling operation on encrypted data\n",
        "def homomorphic_inference(encrypted_X_batches, encrypted_weights, encrypted_bias):\n",
        "    encrypted_predictions = []\n",
        "    for encrypted_X_batch in encrypted_X_batches:\n",
        "        batch_predictions = []\n",
        "        for enc_row in encrypted_X_batch:\n",
        "            enc_result = enc_row.dot(encrypted_weights) + encrypted_bias\n",
        "            batch_predictions.append(enc_result)\n",
        "        encrypted_predictions.append(batch_predictions)\n",
        "    return encrypted_predictions\n",
        "\n",
        "encrypted_predictions_batches = homomorphic_inference(\n",
        "    encrypted_X_test_batches, encrypted_weights, encrypted_bias\n",
        ")\n",
        "\n",
        "# Decrypt Predictions\n",
        "def decrypt_predictions(encrypted_predictions):\n",
        "    decrypted_predictions = []\n",
        "    for batch in encrypted_predictions:\n",
        "        decrypted_batch = [enc_pred.decrypt()[0] for enc_pred in batch]\n",
        "        decrypted_predictions.extend(decrypted_batch)\n",
        "    return decrypted_predictions\n",
        "\n",
        "decrypted_predictions = decrypt_predictions(encrypted_predictions_batches)\n",
        "\n",
        "final_predictions = [1 if pred > 0.5 else 0 for pred in decrypted_predictions]\n",
        "accuracy = np.mean(np.array(final_predictions) == y_test)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CKKS Fully Homomorphic Encryption on nerual network\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tenseal as ts\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#data preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/archive/encoded_data.csv')\n",
        "df = df.drop(columns=['User_ID'])\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target'].values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Define the Simple Neural Network Model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "input_size = X_train.shape[1]\n",
        "model = SimpleNN(input_size)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "#Setting up the encryption domain\n",
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192, #to avoid noise after operations\n",
        "    coeff_mod_bit_sizes=[60, 40, 40, 60] #used for rescaling after operations\n",
        ")\n",
        "context.global_scale = 2**40 #Scaling Factor to handle floating values\n",
        "context.generate_galois_keys()\n",
        "\n",
        "# Encrypt Data\n",
        "def encrypt_data(data, context):\n",
        "    return [ts.ckks_vector(context, row.numpy().tolist()) for row in data]\n",
        "\n",
        "encrypted_X_test = encrypt_data(X_test_tensor, context)\n",
        "\n",
        "encrypted_weights = ts.ckks_vector(context, model.fc.weight.data.numpy().flatten().tolist())\n",
        "encrypted_bias = ts.ckks_vector(context, model.fc.bias.data.numpy().tolist())\n",
        "\n",
        "# CKKS FHE for handling operation on encrypted data\n",
        "def homomorphic_inference(encrypted_X_batches, encrypted_weights, encrypted_bias):\n",
        "    encrypted_predictions = []\n",
        "    for encrypted_X_batch in encrypted_X_batches:\n",
        "        batch_predictions = []\n",
        "        for enc_row in encrypted_X_batch:\n",
        "            enc_result = enc_row.dot(encrypted_weights) + encrypted_bias\n",
        "            batch_predictions.append(enc_result)\n",
        "        encrypted_predictions.append(batch_predictions)\n",
        "    return encrypted_predictions\n",
        "\n",
        "# Encrypting Test Data Batchwise\n",
        "def encrypt_batch(data, context, batch_size=500):\n",
        "    encrypted_data = []\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        batch = data[i:i+batch_size]\n",
        "        encrypted_batch = [ts.ckks_vector(context, row.tolist()) for row in batch]\n",
        "        encrypted_data.append(encrypted_batch)\n",
        "    return encrypted_data\n",
        "\n",
        "encrypted_X_test_batches = encrypt_batch(X_test_tensor, context)\n",
        "\n",
        "encrypted_predictions_batches = homomorphic_inference(\n",
        "    encrypted_X_test_batches, encrypted_weights, encrypted_bias\n",
        ")\n",
        "\n",
        "#Decrypt Predictions\n",
        "def decrypt_predictions(encrypted_predictions):\n",
        "    decrypted_predictions = []\n",
        "    for batch in encrypted_predictions:\n",
        "        decrypted_batch = [enc_pred.decrypt()[0] for enc_pred in batch]\n",
        "        decrypted_predictions.extend(decrypted_batch)\n",
        "    return decrypted_predictions\n",
        "\n",
        "decrypted_predictions = decrypt_predictions(encrypted_predictions_batches)\n",
        "\n",
        "final_predictions = [1 if pred > 0.5 else 0 for pred in decrypted_predictions]\n",
        "accuracy = np.mean(np.array(final_predictions) == y_test)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3IaqoCEN3Nw",
        "outputId": "5c258498-31c6-4fd8-a3fc-e455afb487c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.6552\n",
            "Epoch [20/100], Loss: 0.6213\n",
            "Epoch [30/100], Loss: 0.5909\n",
            "Epoch [40/100], Loss: 0.5635\n",
            "Epoch [50/100], Loss: 0.5390\n",
            "Epoch [60/100], Loss: 0.5168\n",
            "Epoch [70/100], Loss: 0.4968\n",
            "Epoch [80/100], Loss: 0.4786\n",
            "Epoch [90/100], Loss: 0.4621\n",
            "Epoch [100/100], Loss: 0.4470\n",
            "Accuracy: 80.67%\n"
          ]
        }
      ]
    }
  ]
}